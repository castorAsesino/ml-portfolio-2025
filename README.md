# Proyecto 1 â€” CNN con Fashion-MNIST  

## ğŸ“Œ Resumen ejecutivo  
EntrenÃ© una CNN para clasificar ropa con el dataset **Fashion-MNIST**.  
Con 10 Ã©pocas logrÃ© **92.2% de accuracy** y **92.2% de F1 Score**. El modelo anda muy bien en clases fÃ¡ciles como pantalones y bolsos, pero se complica un poco con camisas y camisetas.  

## ğŸ“ Problema y dataset  
- **Problema:** reconocer 10 tipos de prendas.  
- **Dataset:** Fashion-MNIST (70k imÃ¡genes 28x28 en escala de grises).  

## âš™ï¸ MetodologÃ­a  
- **Arquitectura:** CNN con 4 capas conv + BatchNorm y Dropout.  
- **Entrenamiento:** Adam, lr=0.001, batch=64, 10 Ã©pocas.  
- **Recursos:** corrido en CPU comÃºn.  

## ğŸ“Š Resultados  
- Accuracy: **92.2%**  
- F1 Score: **92.2%**  
- Tiempo: ~1242s  
- ParÃ¡metros: ~470k  

Fortalezas: pantalÃ³n, bolso y sandalia casi perfectos.  
Debilidades: confusiÃ³n entre camisa y camiseta.  

## ğŸ“š Lecciones aprendidas  
- BatchNorm + Dropout ayudan bastante.  
- Ver mÃ©tricas por clase muestra dÃ³nde se equivoca.  

## ğŸš€ Trabajo futuro  
- Probar **data augmentation**.  
- Ajustar hiperparÃ¡metros.  
- Usar **modelos preentrenados** para comparar.  

---
# Proyecto 2 â€” DCGAN (CelebA)

## ğŸ“Œ Resumen ejecutivo  
EntrenÃ© un **DCGAN** para generar rostros usando el dataset **CelebA**. El modelo tiene un **generator** y un **discriminator** entrenados con imÃ¡genes reales de 64x64.  
DespuÃ©s de 5 Ã©pocas, las imÃ¡genes generadas todavÃ­a no son muy nÃ­tidas, pero muestran formas de caras.  

## ğŸ“ Problema y dataset  
- **Problema:** generar imÃ¡genes sintÃ©ticas de rostros que se parezcan a los reales.  
- **Dataset:** CelebA (caras de famosos, recortadas a 64x64).  


## âš™ï¸ MetodologÃ­a  
- **Arquitectura:**  
  - Generator: 3.57M parÃ¡metros  
  - Discriminator: 2.76M parÃ¡metros  
  - Latent vector z = 100  
- **Entrenamiento:**  
  - Ã‰pocas: 5  
  - Batch size: 64  
  - Learning rate: 0.0002  
- **Recursos:** entrenado en CPU estÃ¡ndar (tardÃ³ ~1725s).  

## ğŸ“Š Resultados 
- **PÃ©rdida Generator (G):** 7.94  
- **PÃ©rdida Discriminator (D):** 0.60  
- **Tiempo total:** ~1726s  

**Observaciones:**  
- El modelo aprendiÃ³ formas bÃ¡sicas de caras.  
- AÃºn le falta nitidez y detalle.  
- Se necesita mÃ¡s entrenamiento y tal vez mÃ¡s filtros.  


## ğŸ“š Lecciones aprendidas  
- Entrenar GANs es mÃ¡s lento y menos estable que CNNs.  
- El balance entre G y D es clave (si uno gana mucho, el otro falla).  
- Las mÃ©tricas clÃ¡sicas (accuracy, F1) no sirven: se usa la pÃ©rdida y visualizaciÃ³n.  



## ğŸš€ Trabajo futuro  
- Entrenar mÃ¡s Ã©pocas mi compu ya no daba para masss ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­.  
- Usar GPU para mejorar velocidad.  
- Probar mÃ©tricas como **FID** para evaluar calidad de las imÃ¡genes.  
- Usar arquitecturas mÃ¡s modernas (StyleGAN, WGAN-GP).  



# Proyecto 4 â€” LSTM con IMDB 

## ğŸ“Œ Resumen ejecutivo  
EntrenÃ© una **red LSTM bidireccional** para clasificar reseÃ±as de pelÃ­culas (dataset **IMDB**, con ejemplos en 2 clases: positivo/negativo).  
El modelo usa **Embedding + SpatialDropout + LSTM con Dropout**. Con 5 Ã©pocas alcanzÃ³ **85.7% de accuracy en test** y **86.1% de F1 Score**.  

## ğŸ“ Problema y dataset  
- **Problema:** clasificar reseÃ±as de texto como positivas o negativas.  
- **Dataset:** IMDB reviews (ya tokenizado).  

## âš™ï¸ MetodologÃ­a  
- **Arquitectura:** Embedding, SpatialDropout1D, Bidirectional LSTM (96 unidades), capa densa sigmoide.  
- **Entrenamiento:** 5 Ã©pocas, Adam (lr=0.0005), batch=128.  
- **Recursos:** entrenado en CPU estÃ¡ndar.  

## ğŸ“Š Resultados 
- **Accuracy en test:** 85.7%  
- **F1 Score:** 86.1%  
- La matriz de confusiÃ³n muestra buena precisiÃ³n en ambas clases, con algo mÃ¡s de falsos negativos.  

## ğŸ“š Lecciones aprendidas  
- RegularizaciÃ³n con Dropout y EarlyStopping reducen overfitting.  
- F1 es mejor mÃ©trica que accuracy para evaluar balance entre positivo y negativo.  

## ğŸš€ Trabajo futuro  
- Probar **GRU** o Transformers para mejorar performance.  
- Usar embeddings preentrenados (GloVe, Word2Vec).  
- Extender a clasificaciÃ³n multi-clase o anÃ¡lisis mÃ¡s fino de sentimiento.  

